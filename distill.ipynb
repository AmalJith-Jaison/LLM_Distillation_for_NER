{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "165a53fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt template all the mail contents are passed onto the prompt \n",
    "\n",
    "\n",
    "prompt_template =\"\"\"You are assisting the Airline Cargo team in extracting specific business-critical entities from customer emails. Each email consists of a subject and body, both delimited by triple backticks (```). \n",
    "Subject: {subject}\n",
    "From: {from_}\n",
    "To: {to}\n",
    "Body:{body}\n",
    "###################################################### \n",
    "\n",
    "You must return a JSON array of dictionaries, each representing one AWB (Air Waybill) entry with its corresponding entities. The structure should follow these rules: \n",
    "Return a JSON array of dictionaries. \n",
    "Each dictionary must include the extracted AWB and its associated entities. \n",
    "Omit any fields not found in the email; DO NOT assume values. \n",
    "\n",
    "The final output must be pure JSON: no explanations, no backticks, no extra text. \n",
    "The json output should appear as per the following format \n",
    "[ \n",
    "    {{\n",
    "        \"AWB\": \"\", \n",
    "        \"FlightNo\": \"\", \n",
    "        \"Departure-date\": \"\", \n",
    "        \"total-pieces\": , \n",
    "        \"pieces@dimensions\": [\"\"], \n",
    "        \"dimension-unit\": [\"\"], \n",
    "        \"Weight\": , \n",
    "        \"weight-unit\": \"\", \n",
    "        \"special-instruction\": \"\", \n",
    "        \"commodity-description\": \"\", \n",
    "        \"product-code\": \"\", \n",
    "        \"Source\": \"\", \n",
    "        \"Destination\": \"\" \n",
    "    }} \n",
    "] \n",
    "AWB (Air Waybill): \n",
    "Must be 11-digit numbers starting with valid airline prefixes: <AWB_PREFIX>. \n",
    "May be referred to as \"MAWB\" or \"GUIA\". \n",
    "Remove hyphens or spaces. \n",
    "One dictionary per AWB; multiple AWBs = multiple dictionaries.\n",
    "\n",
    "FlightNo:\n",
    "Must start with valid carrier codes: <AIRLINE_PREFIX>. \n",
    "Format: airline code + number \n",
    "do not take the date value for the flight number if there is flight date attached with flight number (eg KE706/18APR in this only take KE706) \n",
    "if no values are found keep as null\n",
    "\n",
    "Departure-date:\n",
    "Extract in YYYY-MM-DD format. \n",
    "If given as a range like 23/24/07, choose the latest date (i.e., 2025-07-24). \n",
    "If given as a relative day (e.g., \"next Monday\"), assume today's date is 2025-03-22 (Saturday) and resolve accordingly.\n",
    "\n",
    "total-pieces:\n",
    "Integer value representing total cargo pieces.\n",
    "\n",
    "pieces@dimensions:\n",
    "\n",
    "May appear as pcs x l x b x h or pcs @ l x b x h. \n",
    "Extract all combinations; prioritize individual dimensions over total.\n",
    "\n",
    "dimension-unit:\n",
    "Supported units: \"CM\", \"M\", \"IN\", \"OTH\". \n",
    "Provide as a list matching the sequence of pieces@dimensions.\n",
    "\n",
    "Weight:\n",
    "If individual weights are given, compute the total. \n",
    "Use chargeable weight (CW) or gross weight (G/W) if explicitly mentioned. \n",
    "If weight is embedded in piece-dimension combos, extract accordingly.\n",
    "\n",
    "weight-unit:\n",
    "Supported values: \"KG\", \"KGS\", \"LBS\", \"OTH\".\n",
    "\n",
    "special-instruction:\n",
    "Extract any special handling notes. \n",
    "Always translate to English.\n",
    "\n",
    "commodity-description:\n",
    "Free text describing the goods. \n",
    "Always translate to English.\n",
    "\n",
    "product-code:\n",
    "If not explicitly given, infer from commodity description: \n",
    "\"GEN\" for general cargo \n",
    "\"HAZ\" for hazardous materials \n",
    "\"DG\" for dangerous goods\n",
    "\n",
    "Source / Destination:\n",
    "Extract from IATA codes in formats like EWR-OME (EWR = Source, OME = Destination). \n",
    "Do not assume source location from sender’s location or from flight number.\n",
    "\n",
    "❗ Important:\n",
    "- Do NOT generate anything other than thejson file\n",
    "- Do **not** use given examples for any fields \n",
    "- Do **not** use any parts from the prompt as fields \n",
    "- Only return the final JSON object. \n",
    "- Do **not** add any explanation, markdown formatting, or code. \n",
    "- Do **not** include backticks (```) or language tags like ```json. \n",
    "- Do **not** generate Python or any other code. \n",
    "- If data is missing, return `null`, but do not fabricate. \n",
    "- Output must be valid and clean JSON. \n",
    "- Only take values from the given mail \n",
    "- must NOT generate any code\n",
    "\n",
    "Must Translate all extracted text into json. \n",
    "Do not fabricate missing values. \n",
    "Always return a clean JSON output only — no markdown, no backticks, no wrapping text. \n",
    "Must Not generate anything other than the base json file. Do NOT generate any code. \n",
    "Only the output is required do not generate anything else\n",
    "\n",
    "since there is a json format given generate just as the json format. Do not generate in loop. if it start to generate in loop stop the generation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def format_prompt(entry):  # Fill the template with the corresponding fields from the email\n",
    "    return prompt_template.format(\n",
    "        subject=entry.get(\"subject\", \"\"),\n",
    "        from_=entry.get(\"from\", \"\"),\n",
    "        to=entry.get(\"To\", \"\"),\n",
    "        body=entry.get(\"body\", \"\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f0212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailDataset(Dataset):  # this class retrieves and encodes the data (email)\n",
    "    def __init__(self, file_path, tokenizer, max_length=2048):\n",
    "        self.samples = []  # Initialize a list to hold tokenized samples\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data_list = json.load(f)  # list of emails\n",
    "            \n",
    "            for data in data_list:\n",
    "                # unwrap nested \"email\"\n",
    "                email_entry = data.get(\"email\", {})  \n",
    "                \n",
    "                prompt = format_prompt(email_entry)\n",
    "                encoding = tokenizer(\n",
    "                    prompt, \n",
    "                    truncation=True, \n",
    "                    max_length=max_length, \n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "                self.samples.append(encoding)  # store samples into \"samples\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)  # total number of samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]  # Retrieve a specific sample by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "teacher_model_name = r\"D:\\models\\mistral7b\" \n",
    "student_model_name = r\"D:\\models\\mistral3b\" \n",
    "\n",
    "# ✅ Load tokenizer from teacher, so both models use 128256 vocab\n",
    "tokenizer = AutoTokenizer.from_pretrained(teacher_model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "\n",
    "student = AutoModelForCausalLM.from_pretrained(\n",
    "    student_model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "teacher = AutoModelForCausalLM.from_pretrained(\n",
    "    teacher_model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "teacher.eval()  # Important to put teacher in eval mode\n",
    "student.resize_token_embeddings(len(tokenizer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9283d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Load dataset using shared tokenizer\n",
    "DATASET_PATH = r\"D:\\New folder (2)\\DATA\\first_1000.json\"\n",
    "dataset = EmailDataset(DATASET_PATH, tokenizer)\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491329c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(student.parameters(), lr=3e-5)\n",
    "kl_loss_fn = torch.nn.KLDivLoss(reduction=\"batchmean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34179bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Student vocab size:\", student.config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb3dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=5\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for batch in loader:\n",
    "        input_ids = batch[\"input_ids\"].squeeze(1).to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].squeeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = teacher(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "        student_logits = student(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "        # Align shapes for next token prediction\n",
    "        student_logits = student_logits[:, :-1, :].contiguous()\n",
    "        teacher_logits = teacher_logits[:, :-1, :].contiguous()\n",
    "        target_ids = input_ids[:, 1:].contiguous()\n",
    "\n",
    "        optimizer.zero_grad()  # zero before backward\n",
    "\n",
    "        loss = kl_loss_fn(\n",
    "            F.log_softmax(student_logits, dim=-1),\n",
    "            F.softmax(teacher_logits, dim=-1)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8b6f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving student model\n",
    "student.save_pretrained(\"./mistral_3b_hope\")\n",
    "tokenizer.save_pretrained(\"./mistral_3b_hope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63fd85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc002c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
