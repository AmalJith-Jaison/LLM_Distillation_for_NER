{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d50d4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaForCausalLM, LlamaTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from textbrewer import GeneralDistiller, TrainingConfig, DistillationConfig\n",
    "import os\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b75fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeDataset(Dataset):\n",
    "    #filepath=r\"D:\\models\\training_data\"\n",
    "    def __init__(self, filepath, tokenizer, max_length=128):\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.lines = [line.strip() for line in f if line.strip()]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.lines[idx]\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        input_ids = enc[\"input_ids\"].squeeze()\n",
    "        attention_mask = enc[\"attention_mask\"].squeeze()\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": input_ids.clone()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a6f101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "#device = \"cuda\"   You can change to 'cuda' if GPU available\n",
    "\n",
    "teacher_path =r\"D:\\models\\llama8b\"\n",
    "teacher = AutoModelForCausalLM.from_pretrained(\n",
    "    teacher_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "# teacher = AutoModelForCausalLM.from_pretrained(teacher_path).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(teacher_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf538d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "student_path =  r\"D:\\models\\llama3b\"\n",
    "student = AutoModelForCausalLM.from_pretrained(\n",
    "    student_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f2f48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_template = \"\"\"You are a helpful assistant. return awb number, :\n",
    "â— Important:\n",
    "- Do **not** use given examples for any fields\n",
    "- Do **not** use any parts from the prompt as fields\n",
    "- Only return the final JSON object.\n",
    "- Do **not** add any explanation, markdown formatting, or code.\n",
    "- Do **not** include backticks (```) or language tags like ```json.\n",
    "- Do **not** generate Python or any other code.\n",
    "- If data is missing, return `null`, but do not fabricate.\n",
    "- Output must be valid and clean JSON.\n",
    "- Only take values from the given mail\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "Subject: {subject}\n",
    "From: {from_}\n",
    "To: {to}\n",
    "Body:{body}\n",
    "######################################################\n",
    " You are assisting the Airline Cargo team in extracting specific business-critical entities from customer emails. Each email consists of a subject and body, both delimited by triple backticks (```).\n",
    " \n",
    "You must return a JSON array of dictionaries, each representing one AWB (Air Waybill) entry with its corresponding entities. The structure should follow these rules:\n",
    "Return a JSON array of dictionaries.\n",
    "Each dictionary must include the extracted AWB and its associated entities.\n",
    "Omit any fields not found in the email; DO NOT assume values.\n",
    " \n",
    "The final output must be pure JSON: no explanations, no backticks, no extra text.\n",
    "The json output should appear as per the following format\n",
    "[\n",
    "    {{\n",
    "        \"AWB\": \"\",\n",
    "        \"FlightNo\": \"\",\n",
    "        \"Departure-date\": \"\",\n",
    "        \"total-pieces\": ,\n",
    "        \"pieces@dimensions\": [\"\"],\n",
    "        \"dimension-unit\": [\"\"],\n",
    "        \"Weight\": ,\n",
    "        \"weight-unit\": \"\",\n",
    "        \"special-instruction\": \"\",\n",
    "        \"commodity-description\": \"\",\n",
    "        \"product-code\": \"\",\n",
    "        \"Source\": \"\",\n",
    "        \"Destination\": \"\"\n",
    "    }}\n",
    "]\n",
    "AWB (Air Waybill):\n",
    "Must be 11-digit numbers starting with valid airline prefixes: <AWB_PREFIX>.\n",
    "May be referred to as \"MAWB\" or \"GUIA\".\n",
    "Remove hyphens or spaces.\n",
    "One dictionary per AWB; multiple AWBs = multiple dictionaries.\n",
    " \n",
    "FlightNo:\n",
    "Must start with valid carrier codes: <AIRLINE_PREFIX>.\n",
    "Format: airline code + number\n",
    "do not take the date value for the flight number if there is flight date attached with flight number (eg KE706/18APR in this only take KE706)\n",
    "if no values are found keep as null\n",
    " \n",
    "Departure-date:\n",
    "Extract in YYYY-MM-DD format.\n",
    "If given as a range like 23/24/07, choose the latest date (i.e., 2025-07-24).\n",
    "If given as a relative day (e.g., \"next Monday\"), assume today's date is 2025-03-22 (Saturday) and resolve accordingly.\n",
    " \n",
    "total-pieces:\n",
    "Integer value representing total cargo pieces.\n",
    " \n",
    "pieces@dimensions:\n",
    "Format: list like [\"2@24x17x9\"].\n",
    "May appear as pcs x l x b x h or pcs @ l x b x h.\n",
    "Extract all combinations; prioritize individual dimensions over total.\n",
    " \n",
    "dimension-unit:\n",
    "Supported units: \"CM\", \"M\", \"IN\", \"OTH\".\n",
    "Provide as a list matching the sequence of pieces@dimensions.\n",
    " \n",
    "Weight:\n",
    "If individual weights are given, compute the total.\n",
    "Use chargeable weight (CW) or gross weight (G/W) if explicitly mentioned.\n",
    "If weight is embedded in piece-dimension combos, extract accordingly.\n",
    " \n",
    "weight-unit:\n",
    "Supported values: \"KG\", \"KGS\", \"LBS\", \"OTH\".\n",
    " \n",
    "special-instruction:\n",
    "Extract any special handling notes.\n",
    "Always translate to English.\n",
    " \n",
    "commodity-description:\n",
    "Free text describing the goods.\n",
    "Always translate to English.\n",
    " \n",
    "product-code:\n",
    "If not explicitly given, infer from commodity description:\n",
    "\"GEN\" for general cargo\n",
    "\"HAZ\" for hazardous materials\n",
    "\"DG\" for dangerous goods\n",
    " \n",
    "Source / Destination:\n",
    "Extract from IATA codes in formats like EWR-OME (EWR = Source, OME = Destination).\n",
    "Do not assume source location from senderâ€™s location or from flight number.\n",
    " \n",
    "Must Translate all extracted text into  json.\n",
    "Do not fabricate missing values.\n",
    "Always return a clean JSON output only â€” no markdown, no backticks, no wrapping text.\n",
    "Must Not generate anything other than the base json file. Do NOT generate any code.\n",
    "Only the output is required do not generate anything else\n",
    " \n",
    "since there is a json format given generate just as the json format. Do not generate in loop. if it start to generate in loop stop the generation.\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d90b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptResponseDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer, prompt_template, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.prompt_template = prompt_template  # <-- store the prompt\n",
    "        self.max_length = max_length\n",
    "        self.samples = []\n",
    "\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        for item in data:\n",
    "            subject = item.get(\"subject\", \"\")\n",
    "            from_ = item.get(\"from\", \"\")\n",
    "            to = item.get(\"to\", \"\")\n",
    "            body = item.get(\"body\", \"\")\n",
    "\n",
    "            self.samples.append({\n",
    "                \"subject\": subject,\n",
    "                \"from_\": from_,\n",
    "                \"to\": to,\n",
    "                \"body\": body\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        subject = sample[\"subject\"]\n",
    "        from_ = sample[\"from_\"]\n",
    "        to = sample[\"to\"]\n",
    "        body = sample[\"body\"]\n",
    "\n",
    "        # Use the shared prompt template\n",
    "        prompt = self.prompt_template.format(subject=subject, from_=from_, to=to, body=body)\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            prompt,\n",
    "            return_tensors='pt',\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": inputs[\"input_ids\"].squeeze(0).clone(),\n",
    "            \"prompt\": prompt,\n",
    "            \"subject\": subject,\n",
    "            \"from_\": from_,\n",
    "            \"to\": to,\n",
    "            \"body\": body\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e11136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"D:\\distil\\structured_outputs.json\"\n",
    "dataset = PromptResponseDataset(file_path, tokenizer, prompt_template)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "# dataset = KnowledgeDataset(r\"C:\\Users\\211369\\Desktop\\program\\distil\\airline.txt\", tokenizer)\n",
    "# train_dataloader = DataLoader(dataset,batch_size=2,shuffle=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8d66c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¨ Prompt:\n",
      " You are a helpful assistant. return awb number, :\n",
      "â— Important:\n",
      "- Do **not** use given examples for any fields\n",
      "- Do **not** use any parts from the prompt as fields\n",
      "- Only return the final JSON object.\n",
      "- Do **not** add any explanation, markdown formatting, or code.\n",
      "- Do **not** include backticks (```) or language tags like ```json.\n",
      "- Do **not** generate Python or any other code.\n",
      "- If data is missing, return `null`, but do not fabricate.\n",
      "- Output must be valid and clean JSON.\n",
      "- Only take values from the given mail\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Subject: [External] RFQ AIRFREIGHT DWC TO DMM , KSA\n",
      "From: Rajesh Kunnumal <rajesh.kunnath@samudera.id>\n",
      "To: \n",
      "Body:ATTENTION: This email originated from a source outside of our organization. Please ensure that you recognize the sender and the content is safe before you open any attachments or click any links.\n",
      "Dear Samina\n",
      "PlsÂ  advise your best rate for below\n",
      "4\n",
      "Destination\n",
      "DMMÂ  Airport , KSA\n",
      "5\n",
      "Actual Commodity\n",
      "Cable reels packedÂ  in pallet\n",
      "6\n",
      "Special Handling Requirement (e.g. Temp Control,Â PAX/CAO DGR, PER, etc.)\n",
      "NA\n",
      "7\n",
      "Actual Weight\n",
      "600 Kgs\n",
      "8\n",
      "Volumetric Weight/DIMS WEIGHT\n",
      "120x100x70 CM\n",
      "9\n",
      "No. of Pieces\n",
      "1Pkgs\n",
      "Thanking you,\n",
      "Rajesh Kunnumal\n",
      "Operation Dept. Head\n",
      "Samudera Logistics DWC LLC\n",
      "Samudera Cargo Services LLC\n",
      "Office # 1109 The Onyx Tower 1\n",
      "Sheikh Zayed Road, The Greens, Dubai 664269, UAE\n",
      "p:\n",
      "+971 4 225 7363\n",
      "m:\n",
      "+971 56 5399 120\n",
      "e:\n",
      "rajesh.kunnath@samudera.id\n",
      "Save Paper - Think before printing this e-mail !!\n",
      "IMPORTANT NOTICE: Â This email and any attachments may contain information that is confidential and privileged. It is intended to be received only by persons entitled to receive\n",
      " the information. If you are not the intended recipient, please delete it from your system and notify the sender. You should not copy it or use it for any purpose nor disclose or distribute its contents to any other person.\n",
      "http://www.samudera.id\n",
      "CONFIDENTIALITY NOTICE:Â  This email, including any attachments, is\n",
      "confidential and may be privileged.Â  If you are not the intended\n",
      "recipient please notify the sender immediately, and please delete it;\n",
      "you should not copy it or use it for any purpose or disclose its\n",
      "contents to any other person.\n",
      "######################################################\n",
      " You are assisting the Airline Cargo team in extracting specific business-critical entities from customer emails. Each email consists of a subject and body, both delimited by triple backticks (```).\n",
      "\n",
      "You must return a JSON array of dictionaries, each representing one AWB (Air Waybill) entry with its corresponding entities. The structure should follow these rules:\n",
      "Return a JSON array of dictionaries.\n",
      "Each dictionary must include the extracted AWB and its associated entities.\n",
      "Omit any fields not found in the email; DO NOT assume values.\n",
      "\n",
      "The final output must be pure JSON: no explanations, no backticks, no extra text.\n",
      "The json output should appear as per the following format\n",
      "[\n",
      "    {\n",
      "        \"AWB\": \"\",\n",
      "        \"FlightNo\": \"\",\n",
      "        \"Departure-date\": \"\",\n",
      "        \"total-pieces\": ,\n",
      "        \"pieces@dimensions\": [\"\"],\n",
      "        \"dimension-unit\": [\"\"],\n",
      "        \"Weight\": ,\n",
      "        \"weight-unit\": \"\",\n",
      "        \"special-instruction\": \"\",\n",
      "        \"commodity-description\": \"\",\n",
      "        \"product-code\": \"\",\n",
      "        \"Source\": \"\",\n",
      "        \"Destination\": \"\"\n",
      "    }\n",
      "]\n",
      "AWB (Air Waybill):\n",
      "Must be 11-digit numbers starting with valid airline prefixes: <AWB_PREFIX>.\n",
      "May be referred to as \"MAWB\" or \"GUIA\".\n",
      "Remove hyphens or spaces.\n",
      "One dictionary per AWB; multiple AWBs = multiple dictionaries.\n",
      "\n",
      "FlightNo:\n",
      "Must start with valid carrier codes: <AIRLINE_PREFIX>.\n",
      "Format: airline code + number\n",
      "do not take the date value for the flight number if there is flight date attached with flight number (eg KE706/18APR in this only take KE706)\n",
      "if no values are found keep as null\n",
      "\n",
      "Departure-date:\n",
      "Extract in YYYY-MM-DD format.\n",
      "If given as a range like 23/24/07, choose the latest date (i.e., 2025-07-24).\n",
      "If given as a relative day (e.g., \"next Monday\"), assume today's date is 2025-03-22 (Saturday) and resolve accordingly.\n",
      "\n",
      "total-pieces:\n",
      "Integer value representing total cargo pieces.\n",
      "\n",
      "pieces@dimensions:\n",
      "Format: list like [\"2@24x17x9\"].\n",
      "May appear as pcs x l x b x h or pcs @ l x b x h.\n",
      "Extract all combinations; prioritize individual dimensions over total.\n",
      "\n",
      "dimension-unit:\n",
      "Supported units: \"CM\", \"M\", \"IN\", \"OTH\".\n",
      "Provide as a list matching the sequence of pieces@dimensions.\n",
      "\n",
      "Weight:\n",
      "If individual weights are given, compute the total.\n",
      "Use chargeable weight (CW) or gross weight (G/W) if explicitly mentioned.\n",
      "If weight is embedded in piece-dimension combos, extract accordingly.\n",
      "\n",
      "weight-unit:\n",
      "Supported values: \"KG\", \"KGS\", \"LBS\", \"OTH\".\n",
      "\n",
      "special-instruction:\n",
      "Extract any special handling notes.\n",
      "Always translate to English.\n",
      "\n",
      "commodity-description:\n",
      "Free text describing the goods.\n",
      "Always translate to English.\n",
      "\n",
      "product-code:\n",
      "If not explicitly given, infer from commodity description:\n",
      "\"GEN\" for general cargo\n",
      "\"HAZ\" for hazardous materials\n",
      "\"DG\" for dangerous goods\n",
      "\n",
      "Source / Destination:\n",
      "Extract from IATA codes in formats like EWR-OME (EWR = Source, OME = Destination).\n",
      "Do not assume source location from senderâ€™s location or from flight number.\n",
      "\n",
      "Must Translate all extracted text into  json.\n",
      "Do not fabricate missing values.\n",
      "Always return a clean JSON output only â€” no markdown, no backticks, no wrapping text.\n",
      "Must Not generate anything other than the base json file. Do NOT generate any code.\n",
      "Only the output is required do not generate anything else\n",
      "\n",
      "since there is a json format given generate just as the json format. Do not generate in loop. if it start to generate in loop stop the generation.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "for batch in dataloader:\n",
    "    prompts = batch[\"prompt\"]  # batch[\"prompt\"] is a list of strings\n",
    "    for prompt in prompts:\n",
    "        print(\"ðŸ“¨ Prompt:\\n\", prompt)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29318e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_response(prompt: str, max_tokens=512):\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = teacher.generate(**inputs, max_new_tokens=max_tokens)\n",
    "#     return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# response = generate_response(prompt)\n",
    "# generated_text = response[len(prompt):].strip()\n",
    "\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd7ab481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 128256])\n",
      "torch.Size([2, 512, 128256])\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "batch = next(iter(train_loader))\n",
    "with torch.no_grad():\n",
    "    t_out = teacher(**batch)\n",
    "s_out = student(**batch)\n",
    "print(t_out.logits.shape)  # [B, T, V]\n",
    "print(s_out.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e23c217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ccb3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(student.parameters(), lr= 5e-5)\n",
    "\n",
    "train_config = TrainingConfig(\n",
    "    device='cuda',                  # or 'cpu' if no GPU\n",
    "    output_dir='./saved_model',\n",
    "    log_dir='./log',\n",
    ")\n",
    "\n",
    "distill_config = DistillationConfig(\n",
    "    temperature=2.0,\n",
    "    kd_loss_type='ce',              # 'ce' for KLDiv, 'mse' for regression\n",
    "    kd_loss_weight=1.0,             # use 1.0 for pure distillation\n",
    "    hard_label_weight=1.0,          # set 0.0 to ignore ground-truth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab25e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_adaptor(batch, model_output):\n",
    "    return {\n",
    "        \"logits\": model_output.logits,\n",
    "        \"labels\": batch.get(\"labels\", None) \n",
    "    }\n",
    "\n",
    "\n",
    "def batch_postprocessor(batch):\n",
    "    return {\n",
    "        \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "        \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "        \"labels\": batch[\"labels\"].to(device),\n",
    "    }\n",
    "def callback(step=None, loss=None, lr=None, model=None):\n",
    "    if loss is not None:\n",
    "        print(f\"[Step {step}] Total Loss: {loss:.4f} | LR: {lr:.6f}\")\n",
    "    else:\n",
    "        print(f\"[Step {step}] Loss is None\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28cf84ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "distiller = GeneralDistiller(\n",
    "    train_config=train_config,\n",
    "    distill_config=distill_config,\n",
    "    model_T=teacher,\n",
    "    model_S=student,\n",
    "    adaptor_T=get_adaptor,\n",
    "    adaptor_S=get_adaptor,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8abcd7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'textbrewer.distiller_general.GeneralDistiller'>\n"
     ]
    }
   ],
   "source": [
    "print(distiller.__class__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a8634bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(10.1875, device='cuda:0', dtype=torch.bfloat16, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "loss, loss_dict = distiller.train_on_batch(batch, {})\n",
    "print(\"Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1df2903d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'textbrewer.distiller_general.GeneralDistiller'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:54, 10.97s/it]\n",
      " 20%|â–ˆâ–ˆ        | 1/5 [00:54<03:39, 54.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 5] Loss is None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 9.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:16, 15.36s/it]\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [02:11<03:23, 67.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 10] Loss is None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 9.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 9.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:07, 13.41s/it]\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [03:18<02:14, 67.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 15] Loss is None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 9.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 9.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 9.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:02, 12.45s/it]\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [04:20<01:05, 65.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 20] Loss is None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 9.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 9.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 9.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 9.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISTILL STEP] Loss: 10.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:56, 11.37s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [05:17<00:00, 63.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 25] Loss is None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(distiller.__class__)\n",
    "from types import MethodType\n",
    "\n",
    "def force_general_train(self, *args, **kwargs):\n",
    "    print(\"âœ… This is GeneralDistiller.train()\")\n",
    "    return GeneralDistiller.train(self, *args, **kwargs)\n",
    "\n",
    "distiller.train = MethodType(force_general_train, distiller)\n",
    "\n",
    "original_train_on_batch = distiller.train_on_batch\n",
    "\n",
    "def wrapped_train_on_batch(self, batch, args):\n",
    "    loss, loss_dict = original_train_on_batch(batch, args)\n",
    "    print(f\"[DISTILL STEP] Loss: {loss.item():.4f}\")\n",
    "    return loss, loss_dict\n",
    "\n",
    "from types import MethodType\n",
    "distiller.train_on_batch = MethodType(wrapped_train_on_batch, distiller)\n",
    "\n",
    "distiller.train_with_num_epochs(\n",
    "    optimizer=optimizer,\n",
    "    scheduler=None,\n",
    "    tqdm_disable=False,\n",
    "    dataloader=train_loader,\n",
    "    max_grad_norm=1.0,\n",
    "    num_epochs=5,\n",
    "    callback=callback,\n",
    "    batch_postprocessor=None\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b57dd37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D:\\\\models\\\\op\\\\tokenizer_config.json',\n",
       " 'D:\\\\models\\\\op\\\\special_tokens_map.json',\n",
       " 'D:\\\\models\\\\op\\\\chat_template.jinja',\n",
       " 'D:\\\\models\\\\op\\\\tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilled_model=r\"D:\\models\\op\"\n",
    "\n",
    "student.save_pretrained(distilled_model)\n",
    "tokenizer.save_pretrained(distilled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a2ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca8456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
